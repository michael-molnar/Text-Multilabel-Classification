{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP - Notebook 4\n",
    "\n",
    "### TFIDF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w7718 w173355 w138132 w232277 w314686 w292000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w195317 w127737 w171593 w22890 w342007 w289824...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w261113 w366000 w378735 w500012 w306830 w20025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w286461 w308610 w27013 w272605 w287214 w15393 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w135431 w115724 w331534 w256214 w71240 w326106...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       no_stop_words\n",
       "0  w7718 w173355 w138132 w232277 w314686 w292000 ...\n",
       "1  w195317 w127737 w171593 w22890 w342007 w289824...\n",
       "2  w261113 w366000 w378735 w500012 w306830 w20025...\n",
       "3  w286461 w308610 w27013 w272605 w287214 w15393 ...\n",
       "4  w135431 w115724 w331534 w256214 w71240 w326106..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the complete dataset with all stop words removed \n",
    "cleaned_data = pd.read_csv ('Data\\X_no_stop_words.csv')\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = cleaned_data['no_stop_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function will take a dataframe and return the number of unique words and the number of times each appears.\n",
    "\"\"\"\n",
    "def get_unique_counts(a_series):\n",
    "    # Create a dictionary\n",
    "    word_count = {}\n",
    "    # Split each row\n",
    "    for row in range(len(a_series.index)):\n",
    "        for word in a_series.iloc[row].split():\n",
    "            # If the word is already in the dictionary, increase its count\n",
    "            if word in word_count:\n",
    "                word_count[word] += 1\n",
    "            # Otherwise, the word is unqiue.  Add it to dictionary\n",
    "            else:\n",
    "                word_count[word] = 1\n",
    "                \n",
    "    print(\"The number of unique words is: \", len(word_count))\n",
    "    print(\"The total number of words is: \", sum(word_count.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words is:  4160\n",
      "The total number of words is:  111719\n"
     ]
    }
   ],
   "source": [
    "get_unique_counts(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing all stop words, we have a total of 111,719 words, 4,160 of which are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the split training data from previous notebook\n",
    "X_train = pd.read_csv ('Data\\X_train_nlp.csv')\n",
    "X_train = X_train['no_stop_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words is:  3716\n",
      "The total number of words is:  78200\n"
     ]
    }
   ],
   "source": [
    "get_unique_counts(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at just our cleaned training data, we have a total of 78,200 words, 3,716 of which are unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF:  Term Frequency Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       w500126 w286461 w145577 w20297 w23969 w109896 ...\n",
       "1       w111248 w300261 w184773 w318673 w234583 w11393...\n",
       "2       w220342 w308610 w127711 w258396 w161756 w33471...\n",
       "3       w300261 w184773 w221585 w318673 w234583 w11393...\n",
       "4       w39222 w553 w273956 w62255 w314686 w392147 w37...\n",
       "                              ...                        \n",
       "5161    w186494 w330842 w116919 w104709 w384021 w27704...\n",
       "5162    w398645 w341569 w252668 w71958 w121735 w250138...\n",
       "5163    w142023 w356690 w309049 w6691 w275199 w286461 ...\n",
       "5164    w373517 w350483 w37419 w358253 w286461 w7718 w...\n",
       "5165    w220342 w127737 w308610 w282206 w236725 w23850...\n",
       "Name: no_stop_words, Length: 5166, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(X_train)\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3716"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF creates one feature for each unique word\n",
    "len(tfidf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5166x3716 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 76591 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The matrix created has a column for each unique word and a row for each row in the dataset\n",
    "tfidf_wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can display the matrix as a dataframe\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(), columns=tfidf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w100060</th>\n",
       "      <th>w1001</th>\n",
       "      <th>w100157</th>\n",
       "      <th>w100187</th>\n",
       "      <th>w100269</th>\n",
       "      <th>w100299</th>\n",
       "      <th>w100527</th>\n",
       "      <th>w10065</th>\n",
       "      <th>w100799</th>\n",
       "      <th>w100966</th>\n",
       "      <th>...</th>\n",
       "      <th>w99014</th>\n",
       "      <th>w99144</th>\n",
       "      <th>w99304</th>\n",
       "      <th>w99321</th>\n",
       "      <th>w99479</th>\n",
       "      <th>w99485</th>\n",
       "      <th>w99560</th>\n",
       "      <th>w99775</th>\n",
       "      <th>w99802</th>\n",
       "      <th>w99857</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5161</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5166 rows × 3716 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      w100060  w1001  w100157  w100187  w100269  w100299  w100527  w10065  \\\n",
       "0         0.0    0.0      0.0      0.0      0.0      0.0      0.0     0.0   \n",
       "1         0.0    0.0      0.0      0.0      0.0      0.0      0.0     0.0   \n",
       "2         0.0    0.0      0.0      0.0      0.0      0.0      0.0     0.0   \n",
       "3         0.0    0.0      0.0      0.0      0.0      0.0      0.0     0.0   \n",
       "4         0.0    0.0      0.0      0.0      0.0      0.0      0.0     0.0   \n",
       "...       ...    ...      ...      ...      ...      ...      ...     ...   \n",
       "5161      0.0    0.0      0.0      0.0      0.0      0.0      0.0     0.0   \n",
       "5162      0.0    0.0      0.0      0.0      0.0      0.0      0.0     0.0   \n",
       "5163      0.0    0.0      0.0      0.0      0.0      0.0      0.0     0.0   \n",
       "5164      0.0    0.0      0.0      0.0      0.0      0.0      0.0     0.0   \n",
       "5165      0.0    0.0      0.0      0.0      0.0      0.0      0.0     0.0   \n",
       "\n",
       "      w100799  w100966  ...  w99014  w99144  w99304  w99321  w99479  w99485  \\\n",
       "0         0.0      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0.0      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0.0      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         0.0      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...      ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "5161      0.0      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5162      0.0      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5163      0.0      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5164      0.0      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5165      0.0      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      w99560  w99775  w99802  w99857  \n",
       "0        0.0     0.0     0.0     0.0  \n",
       "1        0.0     0.0     0.0     0.0  \n",
       "2        0.0     0.0     0.0     0.0  \n",
       "3        0.0     0.0     0.0     0.0  \n",
       "4        0.0     0.0     0.0     0.0  \n",
       "...      ...     ...     ...     ...  \n",
       "5161     0.0     0.0     0.0     0.0  \n",
       "5162     0.0     0.0     0.0     0.0  \n",
       "5163     0.0     0.0     0.0     0.0  \n",
       "5164     0.0     0.0     0.0     0.0  \n",
       "5165     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5166 rows x 3716 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidfvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w100060    0.0\n",
       "w1001      0.0\n",
       "w100157    0.0\n",
       "w100187    0.0\n",
       "w100269    0.0\n",
       "          ... \n",
       "w99485     0.0\n",
       "w99560     0.0\n",
       "w99775     0.0\n",
       "w99802     0.0\n",
       "w99857     0.0\n",
       "Name: 0, Length: 3716, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first row \n",
    "df_tfidfvect.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the sentences are short, almost all of the 3,716 entries will be 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w109896    0.262986\n",
       "w120979    0.117492\n",
       "w121255    0.154337\n",
       "w145577    0.229169\n",
       "w188324    0.214880\n",
       "w193800    0.134432\n",
       "w198565    0.252331\n",
       "w20297     0.164735\n",
       "w237137    0.364992\n",
       "w23969     0.260082\n",
       "w250138    0.124102\n",
       "w255783    0.197789\n",
       "w286461    0.123908\n",
       "w328691    0.407109\n",
       "w380494    0.162436\n",
       "w47586     0.188215\n",
       "w500126    0.261997\n",
       "w83808     0.275548\n",
       "w94172     0.206852\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the non-zero entries\n",
    "df_tfidfvect.iloc[0][df_tfidfvect.iloc[0]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will find the non-zero entries of a row and sort them according to the TF-IDF weights they are given\n",
    "def get_tfid_vect(row):\n",
    "    return df_tfidfvect.iloc[row][df_tfidfvect.iloc[row]!=0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['w328691', 'w237137', 'w83808', 'w109896', 'w500126', 'w23969',\n",
       "       'w198565', 'w145577', 'w188324', 'w94172', 'w255783', 'w47586',\n",
       "       'w20297', 'w380494', 'w121255', 'w193800', 'w250138', 'w286461',\n",
       "       'w120979'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use on the first row\n",
    "get_tfid_vect(0).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF gives a weighting based on how rare a word is in the entire collection of documents.  We can use our embeddings to translate these words into English to examine the weights for this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "\n",
    "# Import GloVe vectors and store in a dictionary \n",
    "glove_embeddings = collections.OrderedDict()\n",
    "with open('Data\\glove.6B.100d.txt', encoding='utf8') as file:\n",
    "    for line in file:\n",
    "        items = line.replace('\\n', '').split(' ')\n",
    "        glove_embeddings[items[0]] = items[1:]\n",
    "    \n",
    "# Import word_embeddings file\n",
    "with open ('Data\\word_embeddings.pkl', 'rb') as file:\n",
    "    embeddings = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can reuse our previous function to use the embeddings and the GloVe vectors to translate the \n",
    "# masked words into English\n",
    "def mask_to_english(inputword):\n",
    "    try:\n",
    "        masked = embeddings[inputword]\n",
    "        word_list = []\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for item in masked:\n",
    "            word_list.append(str(item))\n",
    "    \n",
    "        for key, value in glove_embeddings.items():\n",
    "            if value == word_list:\n",
    "                return key\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define this function to perform this for any given row\n",
    "def get_words(row):\n",
    "    words = {}\n",
    "    for word in get_tfid_vect(row).index:\n",
    "        words[word] = mask_to_english(word)\n",
    "    return pd.Series(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w328691      saxon\n",
       "w237137    twisted\n",
       "w83808     crisply\n",
       "w109896     pastel\n",
       "w500126       None\n",
       "w23969      barely\n",
       "w198565      heavy\n",
       "w145577       full\n",
       "w188324      flare\n",
       "w94172      collar\n",
       "w255783     pocket\n",
       "w47586     sleeves\n",
       "w20297        look\n",
       "w380494      denim\n",
       "w121255       long\n",
       "w193800     sleeve\n",
       "w250138      dress\n",
       "w286461    wearing\n",
       "w120979      shirt\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w328691    0.407109\n",
       "w237137    0.364992\n",
       "w83808     0.275548\n",
       "w109896    0.262986\n",
       "w500126    0.261997\n",
       "w23969     0.260082\n",
       "w198565    0.252331\n",
       "w145577    0.229169\n",
       "w188324    0.214880\n",
       "w94172     0.206852\n",
       "w255783    0.197789\n",
       "w47586     0.188215\n",
       "w20297     0.164735\n",
       "w380494    0.162436\n",
       "w121255    0.154337\n",
       "w193800    0.134432\n",
       "w250138    0.124102\n",
       "w286461    0.123908\n",
       "w120979    0.117492\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We compare this list to the TF-IDF weights\n",
    "get_tfid_vect(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create this function to join the two series into a dataframe by which we can examine the results\n",
    "def get_words_df(row):\n",
    "    result = pd.concat([get_tfid_vect(row), get_words(row)], axis=1)\n",
    "    result.columns=['TF-IDF', 'English Word']\n",
    "    result.index.name = 'Unique Word'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>English Word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w328691</th>\n",
       "      <td>0.407109</td>\n",
       "      <td>saxon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w237137</th>\n",
       "      <td>0.364992</td>\n",
       "      <td>twisted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w83808</th>\n",
       "      <td>0.275548</td>\n",
       "      <td>crisply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w109896</th>\n",
       "      <td>0.262986</td>\n",
       "      <td>pastel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w500126</th>\n",
       "      <td>0.261997</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w23969</th>\n",
       "      <td>0.260082</td>\n",
       "      <td>barely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w198565</th>\n",
       "      <td>0.252331</td>\n",
       "      <td>heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w145577</th>\n",
       "      <td>0.229169</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w188324</th>\n",
       "      <td>0.214880</td>\n",
       "      <td>flare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w94172</th>\n",
       "      <td>0.206852</td>\n",
       "      <td>collar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w255783</th>\n",
       "      <td>0.197789</td>\n",
       "      <td>pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w47586</th>\n",
       "      <td>0.188215</td>\n",
       "      <td>sleeves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w20297</th>\n",
       "      <td>0.164735</td>\n",
       "      <td>look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w380494</th>\n",
       "      <td>0.162436</td>\n",
       "      <td>denim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w121255</th>\n",
       "      <td>0.154337</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w193800</th>\n",
       "      <td>0.134432</td>\n",
       "      <td>sleeve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w250138</th>\n",
       "      <td>0.124102</td>\n",
       "      <td>dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w286461</th>\n",
       "      <td>0.123908</td>\n",
       "      <td>wearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w120979</th>\n",
       "      <td>0.117492</td>\n",
       "      <td>shirt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TF-IDF English Word\n",
       "Unique Word                       \n",
       "w328691      0.407109        saxon\n",
       "w237137      0.364992      twisted\n",
       "w83808       0.275548      crisply\n",
       "w109896      0.262986       pastel\n",
       "w500126      0.261997         None\n",
       "w23969       0.260082       barely\n",
       "w198565      0.252331        heavy\n",
       "w145577      0.229169         full\n",
       "w188324      0.214880        flare\n",
       "w94172       0.206852       collar\n",
       "w255783      0.197789       pocket\n",
       "w47586       0.188215      sleeves\n",
       "w20297       0.164735         look\n",
       "w380494      0.162436        denim\n",
       "w121255      0.154337         long\n",
       "w193800      0.134432       sleeve\n",
       "w250138      0.124102        dress\n",
       "w286461      0.123908      wearing\n",
       "w120979      0.117492        shirt"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_df(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the results for the first row.  The words with the highest weights are words that appear very rarely in the entire collection of our data.  \"saxon\", \"twisted\", \"crisply\" and \"pastel\" are the top four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
